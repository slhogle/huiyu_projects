---
title: "Clustering VOC clusters based on production"
author: "Shane Hogle"
date: today
link-citations: true
abstract: "Try and get deeper insights into VOC production across SynCom species"
---

```{r}
#| output: false
#| warning: false
#| error: false
# Libraries
library(here)
library(tidyverse)
library(vegan)
library(ape)

# read data
vocs <- readr::read_tsv(here::here("data", "vocs.tsv"))
vocs_smiles <- readr::read_tsv(here::here("data", "vocs_SMILES_id.tsv"), col_names=FALSE)
vocs_clusters <- readr::read_tsv(here::here("data", "VOC_fingerprint_clusters.tsv"))
```

```{r}
vocs %>%
  filter(VOC_counts > 0) %>%
  summarize(n_VOCs = n(), .by = "spe.ID") %>%
  arrange(desc(n_VOCs)) %>%
  filter(spe.ID == "ACH1")
```

```{r}
# first we aggregate the spectral counts for each cluster in each species. Here
# we will just use the total sum
vocs_agg <- left_join(vocs, vocs_clusters, by = join_by(VOC_id)) %>%
  summarize(VOC_counts_sm = sum(VOC_counts), .by = c(spe.ID, CLID_0.8))

# normalize the VOC_counts to a max of 1 for each VOC
# so that we only just use information about which species produces
# the most of each VOC, but not the absolute VOC concentrations. I don't really
# know how to interpret the VOC_counts anyway
vocs_agg_rk <- vocs_agg %>%
  group_by(CLID_0.8) %>%
  mutate(VOC_rank = VOC_counts_sm/max(VOC_counts_sm)) %>%
  ungroup()

# log1p transform aggregate counts
# so that we only just use information about which species produces
# the most of each VOC, but not the absolute VOC concentrations. I don't really
# know how to interpret the VOC_counts anyway
vocs_agg_log1p <- vocs_agg %>%
  mutate(VOC_counts_sm = log1p(VOC_counts_sm))
```

# Sparsity of dataset

This data has lots of zeros...

```{r}
vocs_missing <- vocs_agg_rk %>%
  group_by(CLID_0.8) %>%
  count(nonzero = VOC_rank > 0) %>%
  ungroup() %>%
  pivot_wider(names_from = nonzero, values_from = n) %>%
  rename(n_species_detected = `TRUE`, n_species_missing = `FALSE`)

# there are 87 different VOC clusters which are only detected in a single species
vocs_missing %>%
  count(VOC_detected_in_1_sp_only = n_species_detected == 1)
```

```{r}
# on the other hand, there are 16 different VOC clusters that are detected in at
# least 10 different species (so in ~10% of the data set) For example, molecules
# in cut80_002 were produced by 53 different species
vocs_missing %>%
  arrange(desc(n_species_detected))
```

# Dimensionality reduction based on species VOC production

```{r}
# format to wide form for running ordination
vocs_agg_wide <- vocs_missing %>%
  filter(n_species_detected == 1) %>%
  # remove VOCs only detected in 1 species
  anti_join(vocs_agg, ., by = join_by(CLID_0.8)) %>%
  #dplyr::select(-VOC_counts_sm) %>%
  pivot_wider(id_cols = c(spe.ID), names_from = "CLID_0.8", values_from = "VOC_counts_sm") %>%
  column_to_rownames(var = "spe.ID") %>%
  data.frame()

# calculate the frequency of zeros for each VOC column
# high values mean species have many zeros
fz <- colSums(vocs_agg_wide == 0)/nrow(vocs_agg_wide)

vocs_agg_wide_red <- vocs_agg_wide[names(fz[fz < 0.85])] %>%
  filter(rowSums(.) > 0)
```

```{r}
# 57/64 of the VOC clusters have 80% or more zeros in the matrix. This high
# number of zeros will be challenging to deal with... We can consider excluding
# VOC cluster that have ~ 90% or more zeros or we can attempt to do some
# ordination using the full dataset. However, classical euclidean based
# approaches will have very poor performance due to the large number of zeros.
# Much better to try a distance based approach
enframe(colSums(vocs_agg_wide == 0)/nrow(vocs_agg_wide)) %>%
  arrange(value)
```

```{r}
# Only 17% of VOC clusters have fewer than 85% nonzero observations across 113
# species
length(fz[fz < 0.85])/length(fz)
```

## PcOA

```{r}
sp_tr <- decostand(vocs_agg_wide_red, "log", logbase=10)
dst <- vegdist(sp_tr, "jaccard")
# pcoa from vegan::wcmdscale
pcoa_res <- wcmdscale(dst, eig = TRUE)
sppscores(pcoa_res) <- sp_tr
# pcoa from ape
pcoa_res01 <- ape::pcoa(dst)
```

```{r}
round(pcoa_res01$values[1,2], 2)*100
```

```{r}
#| fig.width: 7
#| fig.height: 7
#| warning: false
ordiplot(pcoa_res, type="n",
         xlab=paste0("Dim 1 (", round(pcoa_res01$values[1,2], 2)*100, "% variance)"),
         ylab=paste0("Dim 2 (", round(pcoa_res01$values[2,2], 2)*100, "% variance)")) %>%
  points("sites", pch=16, col="red") %>%
  text("species",  arrows = T, length=0.05, col="blue")
```

## NMDS

```{r}
set.seed(2367)
NMDS <- metaMDS(sp_tr,
                autotransform = FALSE,
                distance = "jaccard",
                trymax = 1000)
```

```{r}
#| fig.width: 7
#| fig.height: 7
#| warning: false
ordiplot(NMDS, type="n") %>%
  points("sites", pch=16, col="red") %>%
  text("species", arrows = T, length=0.05, col="blue")
```

# tSNE

```{r}
library(Rtsne)
sp_tr_mat <- as.matrix(decostand(vocs_agg_wide, "log", logbase=10))

mymat_tsne <- Rtsne::Rtsne(dst,
                           is_distance = TRUE,
                           perplexity = 10,
                           dims = 2,
                           pca_center = FALSE,
                           normalize = FALSE)

mydf_tsne <- data.frame(mymat_tsne$Y) %>%
  cbind(spe.ID = rownames(sp_tr)) %>%
  rename(x = X1, y = X2)

ggplot(mydf_tsne) +
  geom_point(aes(x = x, y = y))
```
